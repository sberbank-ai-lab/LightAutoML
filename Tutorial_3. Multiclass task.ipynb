{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.1. Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install lightautoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.base import AutoML\n",
    "from lightautoml.automl.blend import WeightedBlender\n",
    "from lightautoml.ml_algo.boost_lgbm import BoostLGBM\n",
    "from lightautoml.ml_algo.linear_sklearn import LinearLBFGS\n",
    "from lightautoml.ml_algo.tuning.optuna import OptunaTuner\n",
    "from lightautoml.pipelines.features.lgb_pipeline import LGBSimpleFeatures, LGBAdvancedPipeline\n",
    "from lightautoml.pipelines.features.linear_pipeline import LinearFeatures\n",
    "from lightautoml.pipelines.ml.base import MLPipeline\n",
    "from lightautoml.pipelines.selection.importance_based import ModelBasedImportanceEstimator, ImportanceCutoffSelector\n",
    "from lightautoml.reader.base import PandasToPandasReader\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.utils.profiler import Profiler\n",
    "from lightautoml.utils.timer import PipelineTimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.2. Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 600 # Time in seconds for automl run\n",
    "TARGET_NAME = 'TARGET' # Target column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3. Fix torch number of threads and numpy seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.4. Change profiling decorators settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, profiling decorators are turned off for speed and memory reduction. If you want to see profiling report after using LAMA, you need to turn on the decorators using command below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Profiler()\n",
    "p.change_deco_settings({'enabled': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.5. Example data load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset from the repository if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './example_data/test_data_files'\n",
    "DATASET_NAME = 'sampled_app_train.csv'\n",
    "DATASET_FULLNAME = os.path.join(DATASET_DIR, DATASET_NAME)\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/sberbank-ai-lab/LightAutoML/master/example_data/test_data_files/sampled_app_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not os.path.exists(DATASET_FULLNAME):\n",
    "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "    dataset = requests.get(DATASET_URL).text\n",
    "    with open(DATASET_FULLNAME, 'w') as output:\n",
    "        output.write(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = pd.read_csv(DATASET_FULLNAME)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.6. (Optional) Some user feature preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below shows some user feature preparations to create task more difficult (this block can be omitted if you don't want to change the initial data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\n",
    "data['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n",
    "                    ).astype(str)\n",
    "\n",
    "data['constant'] = 1\n",
    "data['allnan'] = np.nan\n",
    "\n",
    "data['report_dt'] = np.datetime64('2018-01-01')\n",
    "\n",
    "data.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.7. Create fake multiclass target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[TARGET_NAME] = np.where(np.random.rand(data.shape[0]) > .5, 2, data[TARGET_NAME].values)\n",
    "data[TARGET_NAME].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.8. (Optional) Data splitting for train-test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block below can be omitted if you are going to train model only or you have specific train and test files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_data, test_data = train_test_split(data, \n",
    "                                         test_size=TEST_SIZE, \n",
    "                                         stratify=data[TARGET_NAME], \n",
    "                                         random_state=RANDOM_STATE)\n",
    "logging.info('Data splitted. Parts sizes: train_data = {}, test_data = {}'\n",
    "              .format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========= AutoML creation =========\n",
    "\n",
    "![AutoML pipeline for this task](imgs/tutorial_2_pipeline.png)\n",
    "\n",
    "\n",
    "## Step 1. Create Timer for pipeline\n",
    "\n",
    "Here we are going to use strict timer for AutoML pipeline, which helps not to go outside the limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "timer = PipelineTimer(600, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Create feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "timer_gbm = timer.get_task_timer('gbm') # Get task timer from pipeline timer \n",
    "feat_sel_0 = LGBSimpleFeatures()\n",
    "mod_sel_0 = BoostLGBM(timer=timer_gbm)\n",
    "imp_sel_0 = ModelBasedImportanceEstimator()\n",
    "selector_0 = ImportanceCutoffSelector(feat_sel_0, mod_sel_0, imp_sel_0, cutoff=0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1. Create GBMs pipeline for AutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our GBMs ML pipeline:\n",
    "- Advanced features for gradient boosting built on selected features (using step 2) \n",
    "- 2 different models:\n",
    "    * LightGBM with params tuning (using OptunaTuner)\n",
    "    * LightGBM with heuristic params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "feats_gbm_0 = LGBAdvancedPipeline(top_intersections=4, \n",
    "                                  output_categories=True, \n",
    "                                  feats_imp=imp_sel_0)\n",
    "timer_gbm_0 = timer.get_task_timer('gbm')\n",
    "timer_gbm_1 = timer.get_task_timer('gbm')\n",
    "\n",
    "gbm_0 = BoostLGBM(timer=timer_gbm_0)\n",
    "gbm_1 = BoostLGBM(timer=timer_gbm_1)\n",
    "\n",
    "tuner_0 = OptunaTuner(n_trials=20, timeout=30, fit_on_holdout=True)\n",
    "gbm_lvl0 = MLPipeline([\n",
    "        (gbm_0, tuner_0),\n",
    "        gbm_1\n",
    "    ],\n",
    "    pre_selection=selector_0,\n",
    "    features_pipeline=feats_gbm_0, \n",
    "    post_selection=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2. Create linear pipeline for AutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear pipeline:\n",
    "- Using features, special for linear models\n",
    "- LinearLBFGS as a model\n",
    "- Without feature selection here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "feats_reg_0 = LinearFeatures(output_categories=True, \n",
    "                             sparse_ohe='auto')\n",
    "\n",
    "timer_reg = timer.get_task_timer('reg')\n",
    "reg_0 = LinearLBFGS(timer=timer_reg)\n",
    "\n",
    "reg_lvl0 = MLPipeline([\n",
    "        reg_0\n",
    "    ],\n",
    "    pre_selection=None,\n",
    "    features_pipeline=feats_reg_0, \n",
    "    post_selection=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Create multiclass task and reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "task = Task('multiclass', metric = 'crossentropy', ) \n",
    "reader = PandasToPandasReader(task = task, samples = None, max_nan_rate = 1, max_constant_rate = 1,\n",
    "                              advanced_roles = True, drop_score_co = -1, n_jobs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Create blender for 2nd level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combine predictions from different models into one vector we use WeightedBlender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "blender = WeightedBlender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Create AutoML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "automl = AutoML(reader=reader, levels=[\n",
    "    [gbm_lvl0, reg_lvl0]\n",
    "], timer=timer, blender=blender, skip_conn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Train AutoML on loaded data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cell below we train AutoML with target column `TARGET` to receive fitted model and OOF predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "oof_pred = automl.fit_predict(train_data, roles={'target': TARGET_NAME})\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Predict to test data and check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(test_data)\n",
    "logging.debug('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(log_loss(train_data[TARGET_NAME].values, oof_pred.data)))\n",
    "logging.info('TEST score: {}'.format(log_loss(test_data[TARGET_NAME].values, test_pred.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Check AUCs for each class in train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat, df, name in zip([oof_pred, test_pred], [train_data, test_data], ['train', 'test']):\n",
    "    logging.debug('Check aucs {0}...'.format(name))\n",
    "    for cl in range(3):\n",
    "        sc = roc_auc_score((df[TARGET_NAME].values == cl).astype(np.float32), dat.data[:, cl])\n",
    "        logging.info('Class {0} {1} auc score: {2}'.format(cl, name, sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10. Profiling AutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build report here, we must turn on decorators on step 0.4. Report is interactive and you can go as deep into functions call stack as you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p.profile('my_report_profile.html')\n",
    "assert os.path.exists('my_report_profile.html'), 'Profile report failed to build'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix. Profiling report screenshots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading HTML with profiling report, you can see fully folded report (please wait for green LOAD OK text for full load finish). If you click on triangle on the left, it unfolds and look like this:  \n",
    "\n",
    "<img src=\"imgs/tutorial_3_initial_report.png\" alt=\"Initial profiling report\" style=\"width: 500px;\"/>\n",
    "\n",
    "If we go even deeper we will receive situation like this:\n",
    "\n",
    "<img src=\"imgs/tutorial_3_unfolded_report.png\" alt=\"Profiling report after several unfoldings on different levels\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
