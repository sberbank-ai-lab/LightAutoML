{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.0. Install LightAutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment if doesn't clone repository by git. (ex.: colab, kaggle version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install -U lightautoml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.1. Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "import gensim\n",
    "# from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "# from lightautoml.dataset.roles import DatetimeRole\n",
    "# from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.2. Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 300 # Time in seconds for automl run\n",
    "TARGET_NAME = 'TARGET' # Target column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3. Fix torch number of threads and numpy seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.4. Example data load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a dataset from the repository if doesn't clone repository by git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './example_data/test_data_files'\n",
    "DATASET_NAME = 'sampled_app_train.csv'\n",
    "DATASET_FULLNAME = os.path.join(DATASET_DIR, DATASET_NAME)\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/sberbank-ai-lab/LightAutoML/master/example_data/test_data_files/sampled_app_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if not os.path.exists(DATASET_FULLNAME):\n",
    "    os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "    dataset = requests.get(DATASET_URL).text\n",
    "    with open(DATASET_FULLNAME, 'w') as output:\n",
    "        output.write(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = pd.read_csv('./example_data/test_data_files/sampled_app_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.5. (Optional) Some user feature preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below shows some user feature preparations to create task more difficult (this block can be omitted if you don't want to change the initial data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\n",
    "data['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n",
    "                    ).astype(str)\n",
    "\n",
    "data['constant'] = 1\n",
    "data['allnan'] = np.nan\n",
    "\n",
    "data['report_dt'] = np.datetime64('2018-01-01')\n",
    "\n",
    "data.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.6. (Optional) Data splitting for train-test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block below can be omitted if you are going to train model only or you have specific train and test files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_data, test_data = train_test_split(data, \n",
    "                                         test_size=TEST_SIZE, \n",
    "                                         stratify=data[TARGET_NAME], \n",
    "                                         random_state=RANDOM_STATE)\n",
    "logging.info('Data splitted. Parts sizes: train_data = {}, test_data = {}'\n",
    "              .format(train_data.shape, test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.7. (Optional) Reading data from SqlDataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing datasets as SQLite data bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "\n",
    "for _fname in ('train.db', 'test.db'):\n",
    "    if os.path.exists(_fname):\n",
    "        os.remove(_fname)\n",
    "    \n",
    "train_db = sql.connect('train.db')\n",
    "train_data.to_sql('data', train_db)\n",
    "\n",
    "test_db = sql.connect('test.db')\n",
    "test_data.to_sql('data', test_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using dataset wrapper for a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightautoml.reader.tabular_batch_generator import SqlDataSource\n",
    "\n",
    "# train_data is replaced with a wrapper for an SQLAlchemy connection\n",
    "# Wrapper requires SQLAlchemy connection string and query to obtain data from\n",
    "train_data = SqlDataSource('sqlite:///train.db', 'select * from data', index='index')\n",
    "test_data = SqlDataSource('sqlite:///test.db', 'select * from data', index='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========= AutoML preset usage =========\n",
    "\n",
    "\n",
    "## Step 1. Create Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "task = Task('binary', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Setup columns roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roles setup here set target column and base date, which is used to calculate date differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "roles = {'target': TARGET_NAME,\n",
    "         DatetimeRole(base_date=True, seasonality=(), base_feats=False): 'report_dt',\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Create AutoML from preset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create AutoML model here we use `TabularAutoML` preset, which looks like:\n",
    "\n",
    "![TabularAutoML preset pipeline](imgs/tutorial_2_pipeline.png)\n",
    "\n",
    "All params we set above can be send inside preset to change its configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "automl = TabularAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                       tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n",
    "                       lgb_params = {'default_params': {'num_threads': N_THREADS}})\n",
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Predict to test data and check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(roc_auc_score(train_data.data[TARGET_NAME].values, oof_pred.data[:, 0])))\n",
    "logging.info('TEST score: {}'.format(roc_auc_score(test_data.data[TARGET_NAME].values, test_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Profiling AutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build report here, we **must** turn on decorators on step 0.4. Report is interactive and you can go as deep into functions call stack as you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p.profile('my_report_profile.html')\n",
    "assert os.path.exists('my_report_profile.html'), 'Profile report failed to build'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Create AutoML with time utilization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are going to create specific AutoML preset for TIMEOUT utilization (try to spend it as much as possible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "automl = TabularUtilizedAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                       tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n",
    "                       lgb_params = {'default_params': {'num_threads': N_THREADS}})\n",
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Predict to test data and check scores for utilized automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(roc_auc_score(train_data.data[TARGET_NAME].values, oof_pred.data[:, 0])))\n",
    "logging.info('TEST score: {}'.format(roc_auc_score(test_data.data[TARGET_NAME].values, test_pred.data[:, 0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
